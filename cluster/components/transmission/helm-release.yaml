apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: transmission
spec:
  interval: 1m
  chart:
    spec:
      # renovate: registryUrl=https://k8s-at-home.com/charts/
      chart: transmission
      version: 7.1.0
      sourceRef:
        kind: HelmRepository
        name: k8s-at-home
        namespace: flux-system
      interval: 1m
  values:
    image:
      repository: ghcr.io/k8s-at-home/transmission
      tag: v3.00@sha256:6674531cd26f2fc98f3f0894cd13bfeba089aab09faee8a3336be9c2a813ff60
    # To view more enviornment variables see here:
    # https://github.com/k8s-at-home/container-images/tree/main/apps/transmission/settings.json.tmpl
    env:
      TZ: America/Chicago
      TRANSMISSION_INCOMPLETE_DIR_ENABLED: true
      TRANSMISSION_RPC_USERNAME: transmission
      TRANSMISSION_RPC_PASSWORD: ${TRANSMISSION_RPC_PASSWORD}
      TRANSMISSION_RPC_AUTHENTICATION_REQUIRED: true
      TRANSMISSION_PEER_PORT: ${MULLVAD_MOVIES_PEER_PORT}
      TRANSMISSION_PEX_ENABLED: false
      TRANSMISSION_DHT_ENABLED: false
      TRANSMISSION_LPD_ENABLED: false
      TRANSMISSION_UTP_ENABLED: false
    persistence:
      config:
        enabled: true
        size: 100Mi
        accessMode: ReadWriteOnce
        storageClass: ceph-rbd-ssd
        skipuninstall: true
      downloads:
        enabled: true
        existingClaim: downloads-pvc
    ingress:
      main:
        enabled: false
    service:
      main:
        enabled: true
        primary: true
        ports:
          http:
            primary: true
            port: 80
            targetPort: 9091
    addons:
      vpn:
        enabled: true
        # This Should be set to `wireguard`. This will set the add-on to use the default settings for Wireguard based connections.
        type: wireguard
        wireguard:
          image:
            repository: ghcr.io/k8s-at-home/wireguard
            tag: v1.0.20210424@sha256:448045c4270b818ded47ec82b934e7227235402fbefa16e29800c2fb51d6de39
        # If the podSecurityContext is set to run as a different user, make sure to run the Wireguard container as UID/GID 568.
        # This is required for it to be able to read certain configuration files.
        securityContext:
          runAsUser: 568
          runAsGroup: 568
        env:
          # Enable a killswitch that kills all trafic when the VPN is not connected
          KILLSWITCH: "true"
          TZ: America/Chicago
        configFile: |
          [Interface]
          PrivateKey = ${MULLVAD_WIREGUARD_PRIVATE_KEY}
          Address = 10.65.71.69/32,fc00:bbbb:bbbb:bb01::2:4744/128
          DNS = 193.138.218.74
          PostUp = iptables -I OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT && ip6tables -I OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT
          PreDown = iptables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT && ip6tables -D OUTPUT ! -o %i -m mark ! --mark $(wg show %i fwmark) -m addrtype ! --dst-type LOCAL -j REJECT

          [Peer]
          PublicKey = ${MULLVAD_WIREGUARD_PUBLIC_KEY}
          AllowedIPs = 0.0.0.0/0,::0/0
          Endpoint = 68.235.43.130:51820
    resources:
      requests:
        cpu: "500m"
        memory: "800Mi"
      limits:
        cpu: "1000m"
        memory: "1200Mi"

---

apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: flood
spec:
  interval: 1m
  chart:
    spec:
      # renovate: registryUrl=https://k8s-at-home.com/charts/
      chart: flood
      version: 5.3.0
      sourceRef:
        kind: HelmRepository
        name: k8s-at-home
        namespace: flux-system
      interval: 1m
  values:
    image:
      repository: docker.io/jesec/flood
      tag: 4.6.1@sha256:95dd5112471e3afcb85b1760026d9b6370540bb2a238e22b094236d74afb67e0
    env:
      TZ: America/Chicago
      FLOOD_OPTION_RUNDIR: /data
      FLOOD_OPTION_BASEURI: /flood/movies
      FLOOD_OPTION_AUTH: none
      FLOOD_OPTION_TRURL: http://movies-transmission.media.svc.cluster.local/transmission/rpc
      FLOOD_OPTION_TRUSER: transmission
      FLOOD_OPTION_TRPASS: ${TRANSMISSION_RPC_PASSWORD}
    persistence:
      data:
        enabled: true
        type: emptyDir
    ingress:
      main:
        enabled: true
        annotations:
          uroperator.brennerm.github.io/monitor.type: HTTPS
          nginx.ingress.kubernetes.io/auth-response-headers: Authorization
          nginx.ingress.kubernetes.io/auth-signin: https://$host/oauth2/start?rd=$escaped_request_uri
          nginx.ingress.kubernetes.io/auth-url: https://$host/oauth2/auth
          nginx.ingress.kubernetes.io/configuration-snippet: |
            auth_request_set $name_upstream_1 $upstream_cookie_name_1;

            access_by_lua_block {
              if ngx.var.name_upstream_1 ~= "" then
                ngx.header["Set-Cookie"] = "name_1=" .. ngx.var.name_upstream_1 .. ngx.var.auth_cookie:match("(; .*)")
              end
            }
        hosts:
        - host: secure.roomofrequirement.xyz
          paths:
          - path: "/flood/movies"
    service:
      main:
        # type: LoadBalancer
        port:
          port: 80
          targetPort: 3000
    resources:
      requests:
        cpu: "100m"
        memory: "200Mi"
      limits:
        cpu: "200m"
        memory: "400Mi"
    tolerations:
    - key: "RaspberryPi"
      operator: "Exists"
      effect: "NoSchedule"
